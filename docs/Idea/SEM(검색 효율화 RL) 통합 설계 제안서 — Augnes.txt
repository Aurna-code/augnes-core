SEM(검색 효율화 RL) 통합 설계 제안서 — Augnes 로컬

---

## 1. 목적 및 필요성

Augnes의 로컬 에이전트 구조에 SEM(Search-Efficient Model, 검색 효율화 RL) 프레임워크를 통합하여, 외부 검색(툴 사용) 시점의 판단력을 강화하고, 불필요한 호출을 최소화하면서도 답변 정확도를 유지·향상시키는 것이 목표입니다.

## 2. 도입 기대효과

* **검색 API 호출 절감**: 평균 30\~50%의 외부 검색 감소 (벤치마크 기반)
* **정확도 유지/향상**: 내부 장기기억(LTM)·RAG·Proof Stub 등 자체 지식 우선 활용
* **정책 자동화**: 수작업 규칙/통계 기반 분기를 RL 기반의 자가학습 정책으로 진화

## 3. 현행 Augnes 구조 및 Pain-point

* `executor.py`에서 외부 호출 분기(`prove`, `search_code`, `general_query` 등)는 rule/통계 기반으로 동작 중
* LTM/RAG, Proof Stub 등 내부 정보 우선화가 체계화되지 않아, 불필요한 external call 빈도가 있음
* PolicyNet(RL) 실험은 로드맵에는 있으나 아직 본격 도입 전 단계

## 4. SEM(RL 기반 검색 판단) 요약

* **GRPO(Group Relative Policy Optimization)**: PPO 기반, "검색 여부" 결정에 특화된 상대 보상 RL 알고리즘
* **보상 설계**: 정답/오답(정확도) + 검색 필요/불필요(비용) → α, β 하이퍼파라미터로 균형 조절
* **추론 템플릿 분리**: 질문 인식 → 검색 필요 판단 → 내부 추론/외부 검색 → 결과 통합 → 답변 생성

## 5. Augnes-SEM 통합 설계

### 5.1 정책 결정 모듈

* 신규 파일 `core/policy_sem.py` (SEM 정책 네트워크)
* `executor.general_query` 이전에 호출: 내부 vs. 외부 검색 여부 Boolean 반환

### 5.2 보상/피드백 확장

* 평가 피드백 dict에 `search_used: bool`, `policy_action` 필드 추가
* `reward = accuracy_reward + (search_used ? +β : –α)`
* α, β 등 파라미터는 `configs/policy_sem.yaml`로 통합 관리

### 5.3 데이터 및 로그 파이프라인

* `judgments.jsonl` 등 판단 로그에 search 관련 action/결과 기록
* 과거 대화/판단 로그에서 검색 필요성 라벨링 데이터셋 추출, `data/policy_sem/`에 train/valid/test 분리

### 5.4 학습 및 평가

* PoC: 최근 판단 1,000개로 offline RL 학습, 정책 평가
* 메트릭: 검색 호출 감소율, 정확도 변화, 정책 결정 일관성 등

### 5.5 통합 및 확장 로드맵

| 단계 | 작업 내용                     | 예상 기간 |
| -- | ------------------------- | ----- |
| 1  | 데이터셋/로그/Config 준비         | 2주 이내 |
| 2  | 정책 네트워크 PoC 학습/평가         | 1개월   |
| 3  | Executor 연동/Policy API 개발 | 2주    |
| 4  | 통합테스트, CI/CD 적용           | 2주    |
| 5  | 다중 툴(계산기, DB 등) 일반화       | 이후    |

## 6. 리스크 및 대응

* **데이터 부족**: 초기 샘플 확보 후 active learning 도입 검토
* **컴퓨팅 비용**: 소형 네트워크부터 확장, 리소스 최적화
* **보상 민감도**: α/β 자동 튜닝 스크립트 적용

---

본 제안서는 Augnes의 RL 기반 정책 분기(PolicyNet) 실험 단계 및 이후 통합을 위한 실질적 설계 지침을 포함합니다. 실사용 도입 전 PoC 및 단계별 검증을 권장하며, 커스텀 벤치마크와 결합해 지속 개선이 필요합니다.
